# -*- coding: utf-8 -*-
"""classtest_solutions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-1APmVHrkjPyusJQLEvVZfRMtP11tbXQ
"""

import torch
import numpy as np
from torch import nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import helper
import os
import pandas as pd
import cv2
import csv

!git clone https://github.com/YoongiKim/CIFAR-10-images

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py
import importlib
importlib.reload(helper)

# how many samples per batch to load
batch_size = 20
# percentage of training set to use as validation
valid_size = 0.2

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(), # randomly flip and rotate
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])



ptest=[]
ctest=[]
for folder_name in os.listdir("CIFAR-10-images/test/"):
  for files in os.listdir("CIFAR-10-images/test/"+folder_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        path='CIFAR-10-images/test/'+folder_name+'/'+files
        clss=folder_name
        ptest.append(path)
        ctest.append(clss)


dataframe_test = pd.DataFrame({'path':ptest,'class':ctest})

dataframe_test

ptrain=[]
ctrain=[]
for folder_name in os.listdir("CIFAR-10-images/train/"):
  for files in os.listdir("CIFAR-10-images/train/"+folder_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        path='CIFAR-10-images/train/'+folder_name+'/'+files
        clss=folder_name
        ptrain.append(path)
        ctrain.append(clss)


dataframe_train = pd.DataFrame({'path':ptrain,'class':ctrain})

dataframe_train

dataframe_test.to_csv('test_data.csv',index=False)

dataframe_train.to_csv('train_data.csv',index=False)

class MyDataset():
  def __init__(self,image_set,argument=True):
    with open(image_set,"r") as csv_handle:
      csv_reader = csv.reader(csv_handle,delimiter=",")
      self.imgfiles = [eachline[0] for eachline in csv_reader]
    self.argument = argument
  def __len__(self):
    return len(self.imgfiles)
  def __gititem__(self,idx):
    img = imageio.imread(self.imgfiles[idx])
    X = np.asarray(img,dtype=np.float32)
    if self.argument:
      X = do_yarn_transform(X)
    Y = self.classlabels[idx]
    return X,Y

test_data = MyDataset('test_data.csv')
test_data

train_data = MyDataset('train_data.csv')
train_data











